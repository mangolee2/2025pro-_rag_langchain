{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3401aa6",
   "metadata": {},
   "source": [
    "RAG-LangChain llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36f3f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# 단계 1: 문서 로드(Load Documents)\n",
    "loader = PyMuPDFLoader(\"/data1/workspace/pdfs/1-s2.0-S1556086421020682-main.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "# 단계 2: 문서 분할(Split Documents)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# 단계 3: 임베딩(Embedding) 생성\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    "    base_url=\"http://localhost:11434\"  # 기본 Ollama 서버 주소\n",
    ")\n",
    "\n",
    "# 단계 4: DB 생성(Create DB) 및 저장\n",
    "# 벡터스토어를 생성합니다.\n",
    "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)\n",
    "\n",
    "# 단계 5: 검색기(Retriever) 생성\n",
    "# 문서에 포함되어 있는 정보를 검색하고 생성합니다.\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 단계 6: 프롬프트 생성(Create Prompt)\n",
    "# 프롬프트를 생성합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ca39af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from typing import Optional, List, Any\n",
    "import subprocess\n",
    "\n",
    "class OllamaLLM(LLM):\n",
    "    model_name: str = \"gpt-oss\"\n",
    "    temperature: float = 0.0\n",
    "\n",
    "    def _call(\n",
    "        self, \n",
    "        prompt: str, \n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[Any] = None\n",
    "    ) -> str:\n",
    "        result = subprocess.run(\n",
    "            ['ollama', 'run', self.model_name, prompt],\n",
    "            capture_output=True, \n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            raise RuntimeError(f\"Ollama LLM failed: {result.stderr}\")\n",
    "        return result.stdout.strip()\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self):\n",
    "        return {\"model_name\": self.model_name, \"temperature\": self.temperature}\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self):\n",
    "        return \"ollama\"\n",
    "    \n",
    "# 단계 7: 언어모델(LLM) 생성\n",
    "# 모델(LLM) 을 생성합니다.\n",
    "llm = OllamaLLM(model_name=\"gpt-oss\", temperature=0)\n",
    "\n",
    "# 단계 8: 체인(Chain) 생성\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\"  # 또는 \"map_reduce\", \"refine\", \"map_rerank\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bebbf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from typing import Optional, List, Any\n",
    "from langchain.llms.base import LLM\n",
    "\n",
    "class OllamaLLM(LLM):\n",
    "    model_name: str = \"gpt-oss\"\n",
    "    base_url: str = \"http://localhost:11434\"\n",
    "    timeout: int = 300  # 13GB 모델이라 넉넉히 설정\n",
    "    \n",
    "    def _call(\n",
    "        self, \n",
    "        prompt: str, \n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[Any] = None\n",
    "    ) -> str:\n",
    "        url = f\"{self.base_url}/api/generate\"\n",
    "        payload = {\n",
    "            \"model\": self.model_name,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(url, json=payload, timeout=self.timeout)\n",
    "            response.raise_for_status()\n",
    "            return response.json()['response']\n",
    "        except requests.Timeout:\n",
    "            raise RuntimeError(f\"Ollama timed out after {self.timeout}s\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Ollama API error: {str(e)}\")\n",
    "    \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"ollama\"\n",
    "\n",
    "# 사용\n",
    "llm = OllamaLLM(model_name=\"gpt-oss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae605401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "rapamycin\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 커스텀 프롬프트 정의\n",
    "prompt_template = \"\"\"\n",
    "You are a biomedical text analysis assistant specialized in oncology and pharmacological literature.\n",
    "\n",
    "==== Document Excerpt Start ====\n",
    "{context}\n",
    "==== Document Excerpt End ====\n",
    "\n",
    "Task:\n",
    "Extract **generic drug names** that were **experimentally tested, administered, or evaluated for therapeutic efficacy** in the study.\n",
    "\n",
    "Follow these expert-level rules:\n",
    "\n",
    "1. Include only drugs that were **explicitly used or tested** in experiments described in the text — for example:\n",
    "   - cells or mice **treated with** a compound,\n",
    "   - **doses tested** or concentrations reported,\n",
    "   - changes in **tumor volume**, **cancer size**, or **toxicity** after treatment,\n",
    "   - mentions of **responsive** or **resistant** models to the drug.\n",
    "2. Prefer drugs that appear near or within sections describing **quantitative results**, such as tumor growth curves, viability assays, or dose–response data.\n",
    "3. Exclude drugs that are mentioned **only**:\n",
    "   - in mechanistic or pathway descriptions (e.g., “inhibition of mTOR signaling”),\n",
    "   - in speculative statements or future directions,\n",
    "   - in the 'References' section.\n",
    "4. Exclude gene, protein, and target names (e.g., EGFR, MTOR, HER3).\n",
    "5. Do **not infer** or guess drug names unless they are **explicitly described as being used, tested, or evaluated** in the experiment.\n",
    "6. Extract only **unique generic drug names** (e.g., “afatinib”, not “Gilotrif”).\n",
    "\n",
    "---\n",
    "\n",
    "Think step by step:\n",
    "1. Identify all potential drug names.  \n",
    "2. Check if the surrounding text mentions **experimental outcomes or metrics** such as tumor volume, cancer size, toxicity, doses tested, or response/resistance.  \n",
    "3. Keep only those drugs directly tied to these measurable experimental outcomes.  \n",
    "4. Remove any that are only mentioned conceptually (e.g., as part of signaling pathways or hypotheses).  \n",
    "5. List the remaining unique generic drug names.\n",
    "\n",
    "Output format:\n",
    "List all unique generic drug names separated by semicolons (;), with no explanation.\n",
    "\n",
    "Example output:\n",
    "afatinib; erlotinib; gefitinib\n",
    "\n",
    "Question: List all generic drug names that were experimentally tested or evaluated for therapeutic efficacy in this paper.\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# RetrievalQA에 적용\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": PROMPT},\n",
    "    return_source_documents=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 실행\n",
    "question = \"Extract generic drug names from this paper\"\n",
    "response = chain({\"query\": question})\n",
    "print(response['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985cd724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
