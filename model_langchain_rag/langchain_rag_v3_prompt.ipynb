{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdea0d98",
   "metadata": {},
   "source": [
    "### NER-augmented RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75df1aef",
   "metadata": {},
   "source": [
    "ollama llm 모델 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15a0cd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0.5: OllamaLLM 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Step 0.5: OllamaLLM 정의\n",
    "# ==========================\n",
    "import requests\n",
    "from langchain.llms.base import LLM\n",
    "from typing import Optional, List, Any\n",
    "\n",
    "class OllamaLLM(LLM):\n",
    "    model_name: str = \"gpt-oss\"\n",
    "    base_url: str = \"http://localhost:11434\"\n",
    "    timeout: int = 300  # 모델 크기 때문에 충분히 넉넉히 설정\n",
    "    \n",
    "    def _call(\n",
    "        self, \n",
    "        prompt: str, \n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[Any] = None\n",
    "    ) -> str:\n",
    "        url = f\"{self.base_url}/api/generate\"\n",
    "        payload = {\n",
    "            \"model\": self.model_name,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(url, json=payload, timeout=self.timeout)\n",
    "            response.raise_for_status()\n",
    "            return response.json()['response']\n",
    "        except requests.Timeout:\n",
    "            raise RuntimeError(f\"Ollama timed out after {self.timeout}s\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Ollama API error: {str(e)}\")\n",
    "    \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"ollama\"\n",
    "\n",
    "print(\"Step 0.5: OllamaLLM 클래스 정의 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7678cbe2",
   "metadata": {},
   "source": [
    "PDF → RAG → BioNER → 후처리 → 최종 drug list → 정답셋 대비 precision 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32453958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Step 1: 라이브러리 로드\n",
    "# ==========================\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import re\n",
    "\n",
    "# ==========================\n",
    "# Step 2: PDF 로드\n",
    "# ==========================\n",
    "pdf_path = \"/data1/workspace/pdfs/5.pdf\"  # PDF 경로\n",
    "loader = PyMuPDFLoader(pdf_path)\n",
    "docs = loader.load()\n",
    "\n",
    "# ==========================\n",
    "# Step 3: 텍스트 Chunk 분할\n",
    "# ==========================\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# Step 4: 임베딩 + FAISS 벡터스토어\n",
    "# ==========================\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\", base_url=\"http://localhost:11434\")\n",
    "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f137967c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Step 5: BioNER 모델 로드\n",
    "# ==========================\n",
    "ner_model_name = \"d4data/biomedical-ner-all\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(ner_model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    ner_model_name,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "ner_pipe = pipeline(\n",
    "    \"ner\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\"\n",
    ")\n",
    "\n",
    "# ==========================\n",
    "# Step 6: NER 추출 + WordPiece 후처리 함수\n",
    "# ==========================\n",
    "def extract_drugs(text, ner_pipe, min_score=0.9):\n",
    "    ner_results = ner_pipe(text)\n",
    "    # WordPiece 합치기\n",
    "    drugs = []\n",
    "    current_word = \"\"\n",
    "    for token in ner_results:\n",
    "        if token['entity_group'] == 'Medication' and token['score'] >= min_score:\n",
    "            if token['word'].startswith(\"##\"):\n",
    "                current_word += token['word'][2:]\n",
    "            else:\n",
    "                if current_word:\n",
    "                    drugs.append(current_word)\n",
    "                current_word = token['word']\n",
    "    if current_word:\n",
    "        drugs.append(current_word)\n",
    "    # 중복 제거\n",
    "    drugs = list(set(drugs))\n",
    "    return drugs\n",
    "\n",
    "# 테스트\n",
    "test_text = split_documents[0].page_content\n",
    "drugs_in_chunk = extract_drugs(test_text, ner_pipe)\n",
    "# print(\"Step 6: 첫 번째 Chunk에서 추출된 drug names:\", drugs_in_chunk)\n",
    "\n",
    "# ==========================\n",
    "# Step 6: NER 추출 + WordPiece 후처리 함수\n",
    "# ==========================\n",
    "def extract_drugs(text, ner_pipe, min_score=0.9):\n",
    "    ner_results = ner_pipe(text)\n",
    "    # WordPiece 합치기\n",
    "    drugs = []\n",
    "    current_word = \"\"\n",
    "    for token in ner_results:\n",
    "        if token['entity_group'] == 'Medication' and token['score'] >= min_score:\n",
    "            if token['word'].startswith(\"##\"):\n",
    "                current_word += token['word'][2:]\n",
    "            else:\n",
    "                if current_word:\n",
    "                    drugs.append(current_word)\n",
    "                current_word = token['word']\n",
    "    if current_word:\n",
    "        drugs.append(current_word)\n",
    "    # 중복 제거\n",
    "    drugs = list(set(drugs))\n",
    "    return drugs\n",
    "\n",
    "# 테스트\n",
    "test_text = split_documents[0].page_content\n",
    "drugs_in_chunk = extract_drugs(test_text, ner_pipe)\n",
    "# print(\"Step 6: 첫 번째 Chunk에서 추출된 drug names:\", drugs_in_chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d8be6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Step 8: RAG + LLM로 추출된 Drug Names:\n",
      " mAb MDR1-modified chitosan nanoparticles; liensinine; Acetyl-bufalin\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Step 7: 전체 PDF에서 Drug 추출\n",
    "# ==========================\n",
    "all_drugs = []\n",
    "for i, chunk in enumerate(split_documents):\n",
    "    chunk_drugs = extract_drugs(chunk.page_content, ner_pipe)\n",
    "    all_drugs.extend(chunk_drugs)\n",
    "all_drugs = list(set(all_drugs))\n",
    "\n",
    "# ==========================\n",
    "# Step 8: RAG + OllamaLLM 연동 (정리)\n",
    "# ==========================\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# LLM 객체 생성\n",
    "llm = OllamaLLM(model_name=\"gpt-oss\", temperature=0)\n",
    "# print(\"Step 8: OllamaLLM 객체 생성 완료\")\n",
    "\n",
    "# Prompt 정의\n",
    "prompt_template = \"\"\"\n",
    "You are a biomedical text analysis assistant.\n",
    "\n",
    "Your task is to extract **only the drugs that were actually tested, administered, or part of the experiments** in the provided document chunks.\n",
    "Do not include drugs that are mentioned only in the background, references, or comparison sections.\n",
    "\n",
    "==== Document Excerpt Start ====\n",
    "{context}\n",
    "==== Document Excerpt End ====\n",
    "\n",
    "Guidelines:\n",
    "- Extract drugs mentioned in the 'Results' or 'Methods' sections preferably.\n",
    "- Include drugs mentioned in Figures and Tables if they were part of the experiments.\n",
    "- Exclude gene names, proteins, pathways, and drugs only cited from literature.\n",
    "- Merge WordPiece fragments into full drug names.\n",
    "- Remove duplicates.\n",
    "- List up to 3 most relevant drugs if more are found.\n",
    "- Output as a semicolon-separated list.\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\"]\n",
    ")\n",
    "\n",
    "# RetrievalQA 체인 생성\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": PROMPT},\n",
    "    return_source_documents=True,\n",
    "    verbose=True\n",
    ")\n",
    "# print(\"Step 8: RetrievalQA 체인 생성 완료\")\n",
    "\n",
    "# PDF 전체 text 합치기\n",
    "all_text = \" \".join([chunk.page_content for chunk in split_documents])\n",
    "# print(\"Step 8: 모든 chunk 합치기 완료, 길이:\", len(all_text))\n",
    "\n",
    "# RAG + LLM 실행\n",
    "response = chain({\"query\": all_text})\n",
    "rag_drugs = response['result']\n",
    "print(\"Step 8: RAG + LLM로 추출된 Drug Names:\\n\", rag_drugs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a57d93",
   "metadata": {},
   "source": [
    "프롬트 수정 예시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fe1fc0",
   "metadata": {},
   "source": [
    "프롬트 1: 괘 괜찮음, 근데 약물 3개도 많아서 1로 개선함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f5aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a biomedical text analysis assistant.\n",
    "\n",
    "Your task is to extract **only the drugs that were actually tested, administered, or part of the experiments** in the provided document chunks.\n",
    "Do not include drugs that are mentioned only in the background, references, or comparison sections.\n",
    "\n",
    "==== Document Excerpt Start ====\n",
    "{context}\n",
    "==== Document Excerpt End ====\n",
    "\n",
    "Guidelines:\n",
    "- Extract drugs mentioned in the 'Results' or 'Methods' sections preferably.\n",
    "- Include drugs mentioned in Figures and Tables if they were part of the experiments.\n",
    "- Exclude gene names, proteins, pathways, and drugs only cited from literature.\n",
    "- Merge WordPiece fragments into full drug names.\n",
    "- Remove duplicates.\n",
    "- List up to 3 most relevant drugs if more are found.\n",
    "- Output as a semicolon-separated list.\n",
    "\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9053de",
   "metadata": {},
   "source": [
    "프롬트2: 실제 약물 위주, 안 쓰는 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0d6093",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a biomedical text analysis assistant.\n",
    "\n",
    "Your task is to extract **only the drugs that were actually tested, administered, or part of the experiments** in the provided document chunks.\n",
    "Do not include drugs that are mentioned only in the background, discussion, references, or comparison sections.\n",
    "\n",
    "==== Document Excerpt Start ====\n",
    "{context}\n",
    "==== Document Excerpt End ====\n",
    "\n",
    "Guidelines:\n",
    "- Extract drugs mentioned in the 'Results' or 'Methods' sections preferably.\n",
    "- Include drugs mentioned in Figures and Tables only if they were used in the main experiments.\n",
    "- Exclude drugs mentioned only as examples, background information, or in cited papers.\n",
    "- Exclude gene names, proteins, signaling pathways, or assay reagents (e.g., DMSO, PBS, MTT).\n",
    "- If the text describes a combination therapy, include all drugs that were co-administered.\n",
    "- Merge WordPiece fragments into complete drug names.\n",
    "- Remove duplicates.\n",
    "- List up to **3 most relevant drugs** directly used in experiments.\n",
    "- Verify that each extracted term is an **actual drug name or formulation**, not a biological target or herbal component.\n",
    "- Output as a **semicolon-separated list**, without any extra words or explanations.\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852d4504",
   "metadata": {},
   "source": [
    "프롬트3: 1개 약물, 최대3까지 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fb3c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a biomedical text analysis assistant.\n",
    "\n",
    "Your goal is to extract **only the drugs that were experimentally tested, administered, or directly used in the study**.\n",
    "Focus on precision — if uncertain, do not include the drug.\n",
    "\n",
    "==== Document Excerpt Start ====\n",
    "{context}\n",
    "==== Document Excerpt End ====\n",
    "\n",
    "Guidelines:\n",
    "- Prefer drugs explicitly described as being *tested*, *treated*, *administered*, or *used* in the experiments.\n",
    "- Exclude drugs mentioned only in background, discussion, or references.\n",
    "- Ignore drugs that appear as examples, related compounds, or comparative mentions unless they were actually used.\n",
    "- Merge WordPiece fragments into full drug names.\n",
    "- Remove duplicates.\n",
    "- Extract **at least 1** and **at most 3** drug names.\n",
    "# - If no clear experimental drugs are found, return \"None\".\n",
    "- Output only the extracted drug names, separated by semicolons (;), with no extra text or explanation.\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383f39e7",
   "metadata": {},
   "source": [
    "프롬트4 :none 나올경우(어차피 프리시젼0이니), 하나만 : vision 계열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4684da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a biomedical text analysis assistant.\n",
    "\n",
    "Extract drugs that were actually tested or administered in experiments from the following document chunks.\n",
    "Prefer drugs mentioned in 'Results' or 'Methods' sections and in Figures/Tables.\n",
    "Exclude drugs mentioned only in background, references, or literature.\n",
    "\n",
    "==== Document Excerpt Start ====\n",
    "{context}\n",
    "==== Document Excerpt End ====\n",
    "\n",
    "- If no explicit experimental drug names are found, infer the **most likely single drug** that was experimentally tested, based on context clues such as \"treatment\", \"administration\", or \"dose\".\n",
    "- Merge WordPiece fragments into full drug names\n",
    "- Remove duplicates\n",
    "- Output up to 3 most relevant drugs (preferably 1 strong candidate)\n",
    "- Output as a semicolon-separated list (e.g., cisplatin; gefitinib)\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98c33a8",
   "metadata": {},
   "source": [
    "완전 한개만.. (오탐 줄임)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6b7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a biomedical text analysis assistant.\n",
    "\n",
    "Extract **only the single most relevant experimental drug** that was actually tested or administered in the study.\n",
    "Prefer drugs mentioned in 'Results' or 'Methods' sections and in Figures/Tables.\n",
    "Exclude drugs mentioned only in background, references, or literature.\n",
    "\n",
    "==== Document Excerpt Start ====\n",
    "{context}\n",
    "==== Document Excerpt End ====\n",
    "\n",
    "Guidelines:\n",
    "- If multiple drugs are mentioned, choose **the one most central to the experiment**.\n",
    "- If no explicit experimental drug name is found, infer **one likely candidate** based on context clues like \"treatment\", \"administration\", or \"dose\".\n",
    "- Merge WordPiece fragments into a complete drug name.\n",
    "- Output exactly **one drug name** (no lists, no punctuation).\n",
    "\n",
    "Answer: \n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86450f8",
   "metadata": {},
   "source": [
    "1~3개인데, 멀티모달 극단적으로 1개로 가야함. 정답률 낮음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76606f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a biomedical text analysis assistant specialized in identifying **experimentally validated drug names**.\n",
    "\n",
    "Your task is to extract only drug names that were **directly tested, administered, or dosed** in the experiments described below.\n",
    "\n",
    "==== Document Excerpt Start ====\n",
    "{context}\n",
    "==== Document Excerpt End ====\n",
    "\n",
    "Extraction Rules:\n",
    "1. Include a drug **only if** there is experimental evidence such as:\n",
    "   - Dosage (e.g., mg/kg, µM, concentration)\n",
    "   - Treatment phrases (e.g., \"treated with\", \"administered\", \"injected\", \"given\", \"dose of\", \"exposed to\")\n",
    "   - Comparative groups (e.g., \"control vs. cisplatin-treated\")\n",
    "   - Drug combination explicitly tested together\n",
    "2. Exclude drugs mentioned only as:\n",
    "   - Background, literature, hypotheses, or reference drugs\n",
    "   - Future directions or discussion\n",
    "3. Prefer extracting **only one** main experimental drug name.\n",
    "4. Add **up to 2 additional drugs** only if they are clearly and quantitatively involved in the same experiment (e.g., combination therapy).\n",
    "5. Merge fragmented tokens into full drug names (e.g., \"gefi\" + \"tinib\" → \"gefitinib\").\n",
    "6. Remove duplicates and unrelated items.\n",
    "7. If no experimentally verified drug names are found, output “None”.\n",
    "\n",
    "Output Format:\n",
    "- 1–3 drug names, separated by semicolons (`;`)\n",
    "- Preferably 1 strong candidate if the study focuses on a single agent\n",
    "- Example: cisplatin; gefitinib\n",
    "\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ccabe2",
   "metadata": {},
   "source": [
    "비전모델: 3개 뽑길래, 최대1개, 그다음3개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11be015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a biomedical text analysis assistant.\n",
    "\n",
    "Extract the **single most likely experimental drug** that was actually tested or administered in the following document chunks.\n",
    "Prefer drugs mentioned in 'Results' or 'Methods' sections, or in Figures/Tables.\n",
    "Exclude drugs mentioned only in background, references, or literature.\n",
    "\n",
    "==== Document Excerpt Start ====\n",
    "{context}\n",
    "==== Document Excerpt End ====\n",
    "\n",
    "Instructions:\n",
    "- Prioritize identifying **one primary experimental drug**.\n",
    "- Output **only one drug** unless there is clear and explicit evidence of **multiple (up to 3) different experimental drugs** tested.\n",
    "- Merge WordPiece fragments into full drug names.\n",
    "- Remove duplicates and spurious terms (e.g., buffer, saline, vehicle).\n",
    "- If uncertain, choose the **most likely single candidate** based on treatment, administration, or dosage context.\n",
    "- Output as a semicolon-separated list (e.g., cisplatin; gefitinib)\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508c95e0",
   "metadata": {},
   "source": [
    "비전모델 프롬트: 완전 1개 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9779be",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a biomedical text analysis assistant.\n",
    "\n",
    "Your task is to extract **exactly one** experimental drug name that was actually tested or administered in the following document excerpt.\n",
    "\n",
    "==== Document Excerpt Start ====\n",
    "{context}\n",
    "==== Document Excerpt End ====\n",
    "\n",
    "Instructions:\n",
    "- Extract **exactly one** drug name — not two, not three, only one.\n",
    "- Choose the **single most likely experimental drug** based on the context of treatment, administration, or dosage.\n",
    "- If multiple drugs are mentioned, select the **main or most central one** (e.g., the primary treatment or intervention).\n",
    "- Exclude drugs mentioned only in background, literature review, or control conditions.\n",
    "- Do not include vehicles, buffers, or solutions (e.g., saline, DMSO, PBS).\n",
    "- Merge WordPiece fragments into full drug names.\n",
    "- If uncertain, make your **best single guess** rather than listing multiple possibilities.\n",
    "- Output **only the drug name** — no lists, no punctuation, no explanations.\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
